# RadixOx ğŸ¦€âš¡

**A blazingly fast Redis-compatible key-value store. Built with Rust, io_uring, and Adaptive Radix Trees.**

RadixOx is a high-performance in-memory key-value store that speaks the Redis protocol. Drop-in replacement for Redis with **significantly lower tail latency** and **higher throughput**, built on a single-threaded io_uring architecture.

---

## ğŸš€ Performance Benchmarks

Tested with [YCSB](https://github.com/brianfrankcooper/YCSB) (Yahoo! Cloud Serving Benchmark) - industry standard for NoSQL databases.

**Configuration:** 1M records, Workload A (50% read / 50% update), fieldlength=100, 100 client threads, localhost

> **Note on fairness:** RadixOx uses io_uring + SQ_POLL which dedicates a kernel polling thread â€” effectively 2 CPU threads vs Redis's 1. The advantage is real but not strictly iso-resource. Comparison vs `redis-server` running natively (not Docker).

### LOAD Phase (1,000,000 HMSET inserts):

| Metric | Redis | RadixOx | Improvement |
|--------|-------|---------|-------------|
| **Throughput** | 40,538 ops/sec | **76,039 ops/sec** | ğŸš€ **+87%** |
| **Avg Latency** | 2,449 Âµs | **1,309 Âµs** | âš¡ **-47%** |
| **P95 Latency** | 4,671 Âµs | **1,383 Âµs** | âœ… **-70%** |
| **P99 Latency** | 5,859 Âµs | **1,710 Âµs** | âœ… **-71%** |

### RUN Phase (2,000,000 operations â€” 50% HGET / 50% HSET):

| Metric | Redis | RadixOx | Improvement |
|--------|-------|---------|-------------|
| **Throughput** | 136,072 ops/sec | **152,079 ops/sec** | ğŸš€ **+12%** |
| **READ Avg** | 725 Âµs | **655 Âµs** | âš¡ **-10%** |
| **READ P95** | 1,527 Âµs | **712 Âµs** | âœ… **-53%** |
| **READ P99** | 2,079 Âµs | **788 Âµs** | âœ… **-62%** |
| **READ P99.9** | 3,097 Âµs | **1,822 Âµs** | âœ… **-41%** |
| **READ P99.99** | 4,327 Âµs | **3,663 Âµs** | âœ… **-15%** |

**Key Takeaways:**
- ğŸ¯ **Sub-millisecond P99** on reads â€” Redis is at 2ms
- ğŸ’ª **P95 2x better** â€” RadixOx stays flat from avg to P95 (655â†’712Âµs), Redis spikes (725â†’1527Âµs)
- ğŸ“ˆ **ART traversal is O(key_length)** â€” no hash collision, no rehash jitter
- ğŸ”¥ **Load phase 87% faster** â€” no hashtable rehashing as dataset grows

---

## âš¡ Why RadixOx?

### Architecture Advantages

- **ğŸŒ³ Adaptive Radix Tree (ART)** - O(k) lookups where k = key length (not O(1) hash with collisions)
- **ğŸ”¥ io_uring** - Zero-copy async I/O via [monoio](https://github.com/bytedance/monoio), not epoll
- **ğŸ¯ Single-threaded** - No locks, no contention, predictable tail latency
- **ğŸ“Š BTreeMap/BTreeSet** - Deterministic O(log n) for Hash/Set operations, excellent p99.9
- **ğŸ’¾ Zero-copy parsing** - Direct `Bytes` slices, minimal allocations
- **ğŸ”Œ Redis compatible** - Works with `redis-cli`, any Redis client library

### Prefix Operations: Native to ART

Redis stores keys in a flat hash table. `KEYS user:*` must scan **every key in the database** â€” O(N) where N is the total number of keys.

RadixOx stores keys in an Adaptive Radix Tree. `KEYS user:*` traverses directly to the `user:` subtree â€” **O(k)** where k is the number of results.

```bash
# 1M keys total, 1000 start with "user:"
# Redis:    KEYS user:*  â†’  scans 1,000,000 keys   O(N)  ~50ms
# RadixOx:  KEYS user:*  â†’  visits 1,000 keys      O(k)  ~1ms
```

Perfect for workloads with hierarchical keys: `user:123:session`, `config:app:feature`, `cache:region:item`

---

## ğŸ¯ Quick Start

```bash
# Build and run (requires Linux 5.1+ for io_uring)
cargo run --bin radixox-resp --features resp --release

# Test with redis-cli
redis-cli -p 6379 PING              # PONG
redis-cli -p 6379 SET foo bar       # OK
redis-cli -p 6379 GET foo           # "bar"
redis-cli -p 6379 INCR counter      # 1
redis-cli -p 6379 KEYS "user:*"     # Blazingly fast prefix query

# Benchmark
cd ~/ycsb-0.17.0
bin/ycsb.sh load redis -s -P workloads/workloada -p redis.port=6379
bin/ycsb.sh run redis -s -P workloads/workloada -p redis.port=6379
```

---

## ğŸ“š Supported Commands

Full Redis RESP2 protocol support with all major data structures:

### ğŸ”¤ Strings & Keys
| Category | Commands |
|----------|----------|
| **Connection** | `PING` `QUIT` `ECHO` `SELECT` |
| **Strings** | `GET` `SET` `SETNX` `SETEX` `MGET` `MSET` |
| **Counters** | `INCR` `DECR` `INCRBY` `DECRBY` |
| **Keys** | `DEL` `EXISTS` `TYPE` `KEYS` `DBSIZE` `FLUSHDB` |
| **Expiration** | `TTL` `PTTL` `EXPIRE` `PEXPIRE` `PERSIST` |

### ğŸ—‚ï¸ Hash
`HSET` `HMSET` `HGET` `HGETALL` `HDEL` `HEXISTS` `HLEN` `HKEYS` `HVALS` `HMGET` `HINCRBY`

**BTreeMap-based:** O(log n) operations, deterministic ordering, excellent tail latency

### ğŸ“¦ Set
`SADD` `SREM` `SISMEMBER` `SCARD` `SMEMBERS` `SPOP`

**BTreeSet-based:** Ordered iteration, predictable performance

### ğŸ“Š Sorted Set (ZSet)
`ZADD` `ZCARD` `ZRANGE` `ZSCORE` `ZREM` `ZINCRBY`

**Double-indexed:** BTreeSet for range queries + HashMap for O(1) score lookups

### ğŸ“¡ Pub/Sub
`SUBSCRIBE` `UNSUBSCRIBE` `PUBLISH`

**Monoio channels:** Lock-free, single-threaded message passing

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         radixox-resp                                â”‚
â”‚                                                                     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚   monoio     â”‚    â”‚    RESP2     â”‚    â”‚      OxidArt         â”‚ â”‚
â”‚   â”‚  (io_uring)  â”‚â”€â”€â”€â–¶â”‚   Parser     â”‚â”€â”€â”€â–¶â”‚  (Adaptive Radix     â”‚ â”‚
â”‚   â”‚              â”‚    â”‚  zero-copy   â”‚    â”‚   Tree + TTL)        â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â”‚   io_buf â”€â”€â–¶ read_buf â”€â”€â–¶ Frame â”€â”€â–¶ OxidArt â”€â”€â–¶ write_buf â”€â”€â–¶ TCP  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Structures

| Type | Implementation | Complexity | Use Case |
|------|----------------|------------|----------|
| **String** | `Bytes` | O(1) | Raw data, hot path |
| **Int** | `i64` | O(1) | Counters (INCR zero-parse) |
| **Hash** | `BTreeMap<Bytes, Bytes>` | O(log n) | Field-value pairs, YCSB workloads |
| **Set** | `BTreeSet<Bytes>` | O(log n) | Unique members, ordered |
| **ZSet** | `BTreeSet + HashMap` | O(log n) + O(1) | Leaderboards, double-indexed |
| **List** | `VecDeque<Bytes>` | O(1) push/pop | Queues (planned) |

### OxidArt Engine

**Node Structure:** 128 bytes exactly, cache-line optimized
- Path compression for single-child chains
- Two-tier child storage: inline (9 slots) + overflow (118 slots)
- HiSlab allocator with O(1) insert/remove
- Lazy TTL expiration + active eviction (Redis-style)

---

## ğŸ› ï¸ Building

```bash
# Build everything
cargo build --workspace --release

# Build specific components
cargo build -p oxidart                                # ART engine only
cargo build -p radixox-server --bin radixox-resp --release

# Run tests
cargo test -p oxidart
./radixox-server/test_hash.sh
./radixox-server/test_set.sh

# Generate docs
cargo doc --workspace --no-deps --open
```

---

## ğŸ“¦ Workspace Structure

```
radixox/
â”œâ”€â”€ oxidart/            # Adaptive Radix Tree engine (ART + TTL + DFA)
â”œâ”€â”€ radixox-server/     # Server binaries (RESP + legacy protobuf)
â”œâ”€â”€ radixox-common/     # Shared types, protobuf definitions
â”œâ”€â”€ radixox/            # Native Rust client libraries
â””â”€â”€ Cargo.toml          # Workspace manifest
```

---

## ğŸ¯ Use Cases

**Perfect for:**
- ğŸš€ High-throughput APIs (100k+ ops/sec single-thread)
- ğŸ¯ Latency-critical services (p99.9 < 100Âµs)
- ğŸŒ³ Hierarchical key spaces (`user:*`, `cache:*`, prefix operations)
- ğŸ“Š Real-time leaderboards (ZSet with O(1) ZSCORE)
- ğŸ’¾ Session stores, caching layers
- ğŸ”¥ YCSB-style workloads (Hash-heavy)

**Not recommended for:**
- âŒ Multi-threaded workloads (single-threaded by design)
- âŒ Persistence-critical (in-memory only, no RDB/AOF yet)
- âŒ Complex transactions (no Lua scripting)

---

## ğŸ—ºï¸ Roadmap

- [x] âœ… String, Int operations (GET, SET, INCR, DECR)
- [x] âœ… TTL support (EXPIRE, PERSIST, TTL, PTTL)
- [x] âœ… Hash (HSET, HGET, HGETALL, HINCRBY, etc.)
- [x] âœ… Set (SADD, SREM, SMEMBERS, SPOP)
- [x] âœ… Sorted Set (ZADD, ZRANGE, ZINCRBY with double-index)
- [x] âœ… Pub/Sub (SUBSCRIBE, PUBLISH)
- [x] âœ… Pattern matching (KEYS with glob/regex DFA)
- [ ] ğŸš§ List operations (LPUSH, RPUSH, LRANGE)
- [ ] ğŸš§ SCAN cursor-based iteration
- [ ] ğŸš§ Persistence (RDB snapshots, AOF)
- [ ] ğŸš§ Cluster mode
- [ ] ğŸš§ Replication

---

## ğŸ“Š Comparison: RadixOx vs Redis

| Feature | Redis | RadixOx | Winner |
|---------|-------|---------|--------|
| Throughput (run 2M ops) | 136k ops/sec | **152k ops/sec** | ğŸ¦€ **+12%** |
| P99 Latency (read) | 2,079 Âµs | **788 Âµs** | ğŸ¦€ **-62%** |
| P95 Latency (read) | 1,527 Âµs | **712 Âµs** | ğŸ¦€ **-53%** |
| Prefix queries | O(N) scan | **O(k) native** | ğŸ¦€ |
| Data structures | HashMap | **ART + BTree** | ğŸ¦€ |
| Tail latency | Variable | **Predictable** | ğŸ¦€ |
| Multi-threaded | âœ… Yes | âŒ No | ğŸ”´ |
| Persistence | âœ… RDB/AOF | âŒ Not yet | ğŸ”´ |
| Lua scripting | âœ… Yes | âŒ No | ğŸ”´ |
| Ecosystem | ğŸ”´ Massive | ğŸ¦€ Growing | ğŸ”´ |

---

## ğŸ”¬ Technical Details

### Why Single-Threaded?

- **No lock contention** â†’ predictable tail latency
- **Cache-friendly** â†’ all data in L1/L2 cache
- **Simple to reason about** â†’ no race conditions
- **io_uring batching** â†’ syscall amortization
- Modern cores are fast enough for **100k+ ops/sec** single-thread

### Why BTreeMap over HashMap?

- **Deterministic O(log n)** vs O(1) average but O(n) worst-case
- **Better tail latency** (p99.9) - no hash collision spikes
- **Ordered iteration** - HGETALL/HKEYS consistent
- **Cache-friendly** - sequential memory access
- **Perfect for YCSB** - workload A is Hash-heavy

---

## ğŸ“ Requirements

- **Linux 5.1+** (io_uring support)
- **Rust 2024 edition** (nightly not required)
- **x86_64 or ARM64**

---

## ğŸ“œ License

MIT

---

## ğŸ™ Acknowledgments

Built with:
- [monoio](https://github.com/bytedance/monoio) - Async io_uring runtime
- [redis-protocol](https://github.com/aembke/redis-protocol.rs) - RESP parser
- [bytes](https://github.com/tokio-rs/bytes) - Zero-copy byte buffers
- [hislab](https://github.com/hinto-janai/hislab) - Hierarchical slab allocator

Inspired by:
- [Dragonfly](https://github.com/dragonflydb/dragonfly) - Multi-threaded Redis replacement
- [KeyDB](https://github.com/Snapchat/KeyDB) - Multi-threaded Redis fork
- [Skytable](https://github.com/skytable/skytable) - Modern NoSQL database

---

**Made with ğŸ¦€ and âš¡ by the RadixOx team**

*Benchmark your own workload and see the difference!*
